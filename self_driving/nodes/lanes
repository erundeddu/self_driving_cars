#!/usr/bin/env python

"""
PARAMETERS:
    /lanes/hough_threshold (int): minimum voting threshold in Hough space to recognize a line
    /lanes/min_line_length (int): minimum length of a line to be reported
    /lanes/max_line_gap (int): gap between lines to be considered separate
    /lanes/lane_rect (int): half the length in the direction perpendicular to the recognized line to draw a ROI for color detection
    /lanes/min_red_threshold (int): minimum threshold of presence of red pixels to recognize a stop marker
    /lanes/min_yellow_threshold (int): minimum threshold of presence of yellow pixels to recognize a center line
    /lanes/min_hue_red (int): minimum hue value (before 0) for red
    /lanes/max_hue_red (int): maximum hue value (after 0) for red
    /lanes/min_hue_yellow (int): minimum hue value for yellow
    /lanes/max_hue_yellow (int): maximum hue value for yellow

PUBLISHES:
    my_lanes/image_raw (sensor_msgs/Image): Image showing the lanes and stop markers recognized
    my_lanes/vals (std_msgs/Int32MultiArray): key points of the lanes and stop markers detected

SUBSCRIBES:
    prius/front_camera/image_raw (sensor_msgs/Image): Image from the front camera of the Prius

SERVICES:

"""

# the initial structure for this file references https://github.com/rslim087a/Self-Driving-Car-Course-Codes

import rospy
import cv2
import numpy as np
from sensor_msgs.msg import Image
from std_msgs.msg import Int32MultiArray
from cv_bridge import CvBridge, CvBridgeError


def make_points(image, line):
    # image: opencv image
    # line: a slope, intercept tuple
    # returns coordinates of start and end points of the line, using different methods depending on the slope of the line
    slope, intercept = line
    if abs(slope) > 0.2:  # lines that are more vertical fix y coords and find x coords
        y1 = int(image.shape[0])  # bottom of the image
        y2 = int(y1*3/5)         # slightly lower than the middle
        x1 = int((y1 - intercept)/slope)
        x2 = int((y2 - intercept)/slope)
    else:  # lines that are more horizontal fix x coords and find y coords
        x1 = 0  # left of the image
        x2 = image.shape[1]  # right of the image
        y1 = int(x1*slope + intercept)
        y2 = int(x2*slope + intercept)
    return [[x1, y1, x2, y2]]


def canny(img):
    # img: opencv image
    # returns the edges extracted from img using canny edge detector
    gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)  # convert image to grayscale
    kernel = 5  # size of filter for gaussian blur
    blur = cv2.GaussianBlur(img,(kernel, kernel),2)  # blur image to avoid finding edges due to noise
    canny = cv2.Canny(blur, 50, 150)  # canny edge detection step
    return canny


def display_lines(img,lines,types):
    # img: opencv image
    # lines: a list of lists, where each sublist contains end x and y coordinates to plot a line
    # types: a list of integers of same length as lines, where each entry denotes the type of the corresponding line (a center line, a side line, a stop marker)
    # returns an image of the same size as img that plots the lines in different colors depending on their types
    line_image = np.zeros_like(img)
    count = 0
    if lines is not None:
        for line in lines:
            for x1, y1, x2, y2 in line:
                if types[count] == 1:  # 1 is center line, shown in yellow
                    cv2.line(line_image,(x1,y1),(x2,y2),(0,255,255),10)
                elif types[count] == 2:  # 2 is stop marker, shown in red
                    cv2.line(line_image,(x1,y1),(x2,y2),(0,0,255),10)
                elif types[count] == 0:  # side line, show in blue
                    cv2.line(line_image,(x1,y1),(x2,y2),(255,0,0),10)
                elif types[count] == 3:
                    cv2.line(line_image,(x1,y1),(x2,y2),(0,128,255),10)
            count += 1
    return line_image


def region_of_interest(img):
    # img: an opencv image
    # returns a version of img where all pixels outside of the region of interest are set to 0
    # region of interest is hardcoded in this function
    height = img.shape[0]
    width = img.shape[1]
    mask = np.zeros_like(img)
    # this region of interest was fine tuned so that it discards bottom parts of the image that come from the front of the car and top parts of the image that are not relevant
    trapz = np.array([[ 
    (0, 109*height//160),
    (0, 9.5*height//20),
    (800, 9.5* height//20),
    (800, 109*height//160),]], np.int32)
    #
    cv2.fillPoly(mask, trapz, 255)
    masked_image = cv2.bitwise_and(img, mask)
    return masked_image


def average_slope_intercept(image, lines):
    # TODO: comment this function
    candidate_stop_lines = []  # a list of approximately horizontal lines (slope, intercept), some of which may correspond to the stop markers
    filtered_lines = []  # a list of more vertical lines (slope, intercept) that correspond to the center and side lane-divider lines
    # divide all lines between the two lists above depending on their slope
    for line in lines:
        for x1, y1, x2, y2 in line:
            fit = np.polyfit((x1,x2), (y1,y2), 1)
            slope = fit[0]
            intercept = fit[1]
            if abs(slope) > 0.7:  # more vertical line
                filtered_lines.append((slope, intercept))
            elif abs(slope) < 0.15:  # more horizontal line
                candidate_stop_lines.append((slope, intercept))
    avg_lines = []
    # parameters
    d_slope = 15*3.14159/180
    d_inter = 100
    d_x = 10
    for line in filtered_lines:
        did_append = False
        for sub_list in avg_lines:
            for compare_line in sub_list:
                y = int((image.shape[0])*3/5)
                slope_cp = compare_line[0]
                intercept_cp = compare_line[1]
                slope_ln = line[0]
                intercept_ln = line[1]
                x_cp = int((y - intercept_cp)/slope_cp)
                x_ln = int((y - intercept_ln)/slope_ln)
                if abs(x_cp - x_ln) > d_x:
                    break
            else:
                sub_list.append(line)
                did_append = True
        if not did_append:
            avg_lines.append([line])
    
    avg_stop_lines = []
    d_y = 30
    for line in candidate_stop_lines:
        did_append = False
        for sub_list in avg_stop_lines:
            for compare_line in sub_list:
                x1 = 0         
                x2 = image.shape[1]
                slope_cp = compare_line[0]
                intercept_cp = compare_line[1]
                slope_ln = line[0]
                intercept_ln = line[1]
                y_cp_1 = int(intercept_cp + slope_cp*x1)
                y_cp_2 = int(intercept_cp + slope_cp*x2)
                y_ln_1 = int(intercept_ln + slope_cp*x1)
                y_ln_2 = int(intercept_ln + slope_cp*x2)
                if abs(y_cp_1 - y_ln_1) > d_y or abs(y_cp_2 - y_ln_2) > d_y:
                    break
            else:
                sub_list.append(line)
                did_append = True
        if not did_append:
            avg_stop_lines.append([line])

    avg_lines_out = []
    stop_lines_out = []
    for sub_list in avg_lines:
        fit_average = np.average(sub_list, axis=0)
        line = make_points(image, fit_average)
        avg_lines_out.append(line)
    for sub_list in avg_stop_lines:
        fit_average = np.average(sub_list, axis=0)
        line = make_points(image, fit_average)
        stop_lines_out.append(line)
    return avg_lines_out, stop_lines_out


def determine_line_type(img, ln, trapz_type, color_low_1, color_high_1, color_threshold, color_low_2=None, color_high_2=None):
    # img: an opencv image
    # ln: a line defined by [[x1, y1, x2, y2]] end points
    # trapz_type: a switch to use different ROI around the line depending on whether the line is more vertical or horizontal
    # color_low_1: [H, S, V] lower limit 1
    # color_high_1: [H, S, V] upper limit 1
    # color_threshold: if there are more pixels in the desired color range than this number, return True
    # color_low_2: [H, S, V] lower limit 2 (to be used if H is wrapping around 0)
    # color_high_2: [H, S, V] upper limit 2 (to be used if H is wrapping around 0)
    # return True if line is made up of enough pixels in the color ranges provided, False otherwise
    height = img.shape[0]
    width = img.shape[1]
    mask = np.zeros_like(img)
    pts = ln[0]
    if trapz_type == 0:
        # for vertical lines
        trapz = np.array([[[
            (pts[0]-lane_rect, pts[1]),
            (pts[2]-lane_rect, pts[3]),
            (pts[2]+lane_rect, pts[3]),
            (pts[0]+lane_rect, pts[1]),]]], np.int32)
    elif trapz_type == 1:
        # for horizontal lines
        trapz = np.array([[[
            (pts[0], max(pts[1]-lane_rect,0)),
            (pts[2], max(pts[1]-lane_rect,0)),
            (pts[2], min(pts[3]+lane_rect,height)),
            (pts[0], min(pts[3]+lane_rect,height)),]]], np.int32)
    cv2.fillPoly(mask, trapz, [255,255,255])
    masked_image = cv2.bitwise_and(img, mask)  # get region of interest around line
    hsv_frame = cv2.cvtColor(masked_image, cv2.COLOR_BGR2HSV)  # convert ROI to HSV for color detection
    color_mask_1 = cv2.inRange(hsv_frame, color_low_1, color_high_1)  # color mask 1 (two are provided in case hue wraps around 0)
    if color_low_2 is not None and color_high_2 is not None:
        color_mask_2 = cv2.inRange(hsv_frame, color_low_2, color_high_2)
        color_mask = color_mask_1 | color_mask_2
    else:
        color_mask = color_mask_1
    color = cv2.bitwise_and(img, img, mask=color_mask)  # filter out desired color
    num_color = np.sum(color_mask)  # sum the number of pixels with the desired color
    if num_color > color_threshold:  # compare to threshold
        return True  # true: the line is in the color range desired
    else:
        return False


def callback(data):
    # process incoming image, find and publish lines
    try:
        cv_image = bridge.imgmsg_to_cv2(data, "bgr8")
    except CvBridgeError as e:
        print(e)
    (rows,cols,channels) = cv_image.shape
    canny_image = canny(cv_image)
    cropped_canny = region_of_interest(canny_image)
    lines = cv2.HoughLinesP(cropped_canny, 2, np.pi/180, hough_threshold, np.array([]), minLineLength=min_line_length,maxLineGap=max_line_gap)
    if lines is not None:
        averaged_lines, stops = average_slope_intercept(cv_image, lines)
        types = []
        for ln in averaged_lines:  # for vertical lines, divide between central (yellow) and side lines
            if determine_line_type(cv_image, ln, 0, low_yellow, high_yellow, min_yellow_threshold):
                types.append(1)
            else:
                types.append(0)
        for ln in stops:  # for horizontal lines, find the stop markers
            if determine_line_type(cv_image, ln, 1, low_red_1, high_red_1, min_red_threshold, low_red_2, high_red_2):
                types.append(2)
                averaged_lines.append(ln)
            elif determine_line_type(cv_image, ln, 1, low_yellow, high_yellow, 3*min_yellow_threshold):
                types.append(3)
                averaged_lines.append(ln)
        line_image = display_lines(cv_image, averaged_lines, types)
        combined_image = cv2.addWeighted(cv_image, 0.8, line_image, 1, 1)
        lane_data = Int32MultiArray()
        lane_data_array = []
        for ii in range(len(types)):
            if types[ii] == 0 or types[ii] == 1:  
                lane_data_array.append(averaged_lines[ii][0][2])
            else:  # for stop markers, append y coord
                lane_data_array.append(averaged_lines[ii][0][1])
            lane_data_array.append(types[ii])  # after the coord, append the type of the line
        lane_data.data = lane_data_array
        lanes_pub.publish(lane_data)
    else:  # if no lines detected
        combined_image = cv_image

    # resize
    original_width = combined_image.shape[1]
    new_width = min(400, combined_image.shape[1])
    scale = new_width/original_width
    new_height = int(combined_image.shape[0]*scale)
    dim = (new_width, new_height)
    combined_image = cv2.resize(combined_image, dim, interpolation=cv2.INTER_AREA)

    try:
        image_pub.publish(bridge.cv2_to_imgmsg(combined_image, "bgr8"))  # convert to ros image and publish
    except CvBridgeError as e:
        print(e)


if __name__=="__main__":
    rospy.init_node('lanes')
    image_pub = rospy.Publisher("/my_lanes/image_raw",Image,queue_size=1)
    bridge = CvBridge()  # used to convert ROS images to opencv images and vice versa
    image_sub = rospy.Subscriber("/prius/front_camera/image_raw",Image,callback)
    lanes_pub = rospy.Publisher("/my_lanes/vals",Int32MultiArray,queue_size=2)

    hough_threshold = rospy.get_param("lanes/hough_threshold", 100)
    min_line_length = rospy.get_param("lanes/min_line_length", 40)
    max_line_gap = rospy.get_param("lanes/max_line_gap", 5)
    lane_rect = rospy.get_param("lanes/lane_rect", 8)
    min_red_threshold = rospy.get_param("lanes/min_red_threshold", 300000)
    min_yellow_threshold = rospy.get_param("lanes/min_yellow_threshold", 60000)
    min_hue_red = rospy.get_param("lanes/min_hue_red", 170)
    max_hue_red = rospy.get_param("lanes/max_hue_red", 10)
    min_hue_yellow = rospy.get_param("lanes/min_hue_yellow", 25)
    max_hue_yellow = rospy.get_param("lanes/max_hue_yellow", 40)

    low_yellow = np.array([min_hue_yellow, 150, 64])
    high_yellow = np.array([max_hue_yellow, 255, 255])
    low_red_1 = np.array([min_hue_red,220,60])
    high_red_1 = np.array([180,255,255])
    low_red_2 = np.array([0,220,60])
    high_red_2 = np.array([max_hue_red,255,255])

    rospy.spin()