#!/usr/bin/env python

"""
PARAMETERS:
    /lanes/hough_threshold (int): minimum voting threshold in Hough space to recognize a line
    /lanes/min_line_length (int): minimum length of a line to be reported
    /lanes/max_line_gap (int): gap between lines for them to be considered separate
    /lanes/lane_rect (int): half the length in the direction perpendicular to the recognized line to draw a ROI for color detection
    /lanes/min_red_threshold (int): minimum threshold of presence of red pixels to recognize a stop marker
    /lanes/min_yellow_threshold (int): minimum threshold of presence of yellow pixels to recognize a center line
    /lanes/min_hue_red (int): minimum hue value (before 0) for red
    /lanes/max_hue_red (int): maximum hue value (after 0) for red
    /lanes/min_hue_yellow (int): minimum hue value for yellow
    /lanes/max_hue_yellow (int): maximum hue value for yellow
    /lanes/min_vertical_slope (float): minimum magnitude (absolute value) of the slope of a line for it to be labeled as vertical
    /lanes/max_horizontal_slope (float): maximum magnitude (absolute value) of the slope of a line for it to be labeled as horizontal
    /lanes/same_horizontal_line_gap (int): maximum vertical distance (in pixels) for two horizontal lines to be treated as one
    /lanes/same_vertical_line_gap (int): maximum horizontal distance (in pixels) for two vertical lines to be treated as one

PUBLISHES:
    my_lanes/image_raw (sensor_msgs/Image): Image showing the lanes and stop markers recognized
    my_lanes/vals (std_msgs/Int32MultiArray): key points of the lanes and stop markers detected

SUBSCRIBES:
    prius/front_camera/image_raw (sensor_msgs/Image): Image from the front camera of the Prius

SERVICES:

"""

# the initial structure for this node (use of Hough Transforms, classifying lines by slope, averaging neighbor lines) takes inspiration from https://github.com/rslim087a/Self-Driving-Car-Course-Codes/tree/master/Section%205%20Resources%20(Finding%20Lanes)/Source%20Code

import rospy
import cv2
import numpy as np
from sensor_msgs.msg import Image
from std_msgs.msg import Int32MultiArray
from cv_bridge import CvBridge, CvBridgeError


def make_points(image, line):
    """
    Converts a slope-intercept description of a line into a 2 end-points description, using different methods depending on the slope of the line

    :param image: the opencv image from which lines are extracted
    :param line: a (slope, intercept) tuple defining a line on the image
    :return: a list in a list containing x and y coordinates of end point 1, x and y coordinates of end point 2
    """
    slope, intercept = line
    if abs(slope) > 0.2:  # lines that are more vertical fix y coords and find x coords
        y1 = int(image.shape[0])  # bottom of the image
        y2 = int(y1*3/5)         # slightly lower than the middle
        x1 = int((y1 - intercept)/slope)
        x2 = int((y2 - intercept)/slope)
    else:  # lines that are more horizontal fix x coords and find y coords
        x1 = 0  # left of the image
        x2 = image.shape[1]  # right of the image
        y1 = int(x1*slope + intercept)
        y2 = int(x2*slope + intercept)
    return [[x1, y1, x2, y2]]


def canny(img):
    """
    Applies Canny edge detector to an opencv image and returns the image of edges

    :param img: an opencv image
    :return: an opencv image of edges extracted using Canny edge detector
    """
    gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)  # convert image to grayscale
    kernel = 5  # size of filter for gaussian blur
    blur = cv2.GaussianBlur(img,(kernel, kernel),2)  # blur image to avoid finding edges due to noise
    canny = cv2.Canny(blur, 50, 150)  # canny edge detection step
    return canny


def display_lines(img, lines, types):
    """
    Applies Canny edge detector to an opencv image and returns the image of edges

    :param img: an opencv image
    :param lines: a list of lines, each defined by a list containing x and y coordinates of the first and second endpoints ([[x1, y1, x2, y2]])
    :param types: a list of integers of same length as lines, where each entry labels the type of the corresponding line (a center line, a side line, a stop marker...)
    :return: an opencv image of the same size as img that plot the lines in different colors depending on their types
    """
    line_image = np.zeros_like(img)  # create blank image
    count = 0
    if lines is not None:
        for line in lines:
            for x1, y1, x2, y2 in line:
                if types[count] == 1:  # 1 is center line, shown in yellow
                    cv2.line(line_image,(x1,y1),(x2,y2),(0,255,255),10)
                elif types[count] == 2:  # 2 is stop marker, shown in red
                    cv2.line(line_image,(x1,y1),(x2,y2),(0,0,255),10)
                elif types[count] == 0:  # side line, shown in blue
                    cv2.line(line_image,(x1,y1),(x2,y2),(255,0,0),10)
                elif types[count] == 3:  # 3 is center line when seen horizontally (at an intersection), shown in orange
                    cv2.line(line_image,(x1,y1),(x2,y2),(0,128,255),10)
            count += 1
    return line_image


def region_of_interest(img):
    """
    Crops the opencv image from the front camera of the car to discard irrelevant top and bottom regions

    :param img: an opencv image
    :return: a modified version of img where all pixels outside of the region of interest are set to 0
    """
    height = img.shape[0]
    width = img.shape[1]
    mask = np.zeros_like(img)  # create blank image
    # this region of interest was fine tuned so that it discards bottom parts of the image that come from the front of the car and top parts of the image that are not relevant
    trapz = np.array([[ 
    (0, 109*height//160),
    (0, 9.5*height//20),
    (800, 9.5* height//20),
    (800, 109*height//160),]], np.int32)
    #
    cv2.fillPoly(mask, trapz, 255)
    masked_image = cv2.bitwise_and(img, mask)
    return masked_image


def average_slope_intercept(image, lines):
    """
    Filters detected lines into more vertical and more horizontal lines, eliminating lines that would not correspond to lane lines
    Averages lines that are similar to each other into a single line

    :param image: an opencv image from which lines were identified
    :param lines: a list of lines, each defined by a list containing x and y coordinates of the first and second endpoints ([[x1, y1, x2, y2]])
    :return: a list of more vertical lines and a list of more horizontal lines, where adjacent lines have been averaged into a single line
    """
    horizontal_lines = []  # a list of approximately horizontal lines (slope, intercept), some of which may correspond to the stop markers
    vertical_lines = []  # a list of more vertical lines (slope, intercept) that correspond to the center and side lane-divider lines
    # divide all lines between the two lists above depending on their slope
    for line in lines:
        for x1, y1, x2, y2 in line:
            # filter all lines depending on slope
            fit = np.polyfit((x1,x2), (y1,y2), 1)
            slope = fit[0]
            intercept = fit[1]
            if abs(slope) > min_vertical_slope:  # more vertical lines
                vertical_lines.append((slope, intercept))
            elif abs(slope) < max_horizontal_slope:  # more horizontal lines
                horizontal_lines.append((slope, intercept))
    avg_vertical_lines = []  # list to include averaged vertical lines
    for line in vertical_lines:
        did_append = False  # if True: line was found to be similar to another line already included in the averaged lines list
        for sub_list in avg_vertical_lines:  # each sublist contains a cluster of lines found to be similar and to be averaged later
            for compare_line in sub_list:
                y = int((image.shape[0])*3/5)
                slope_cp = compare_line[0]
                intercept_cp = compare_line[1]
                slope_ln = line[0]
                intercept_ln = line[1]
                # compare the two top x coordinates (in a prospective view, these are similar for adjacent lines)
                x_cp = int((y - intercept_cp)/slope_cp)
                x_ln = int((y - intercept_ln)/slope_ln)
                if abs(x_cp - x_ln) > d_x:  # if the lines are not similar (x coordinates are too far), end loop
                    break
            else:  # if loop was never broken, the lines are similar: append the new line in the compared sublist
                sub_list.append(line)
                did_append = True
        if not did_append:  # if the new line is not similar to any line, append it as a separate entry
            avg_vertical_lines.append([line])
    
    avg_horizontal_lines = []  # list to include averaged horizontal lines
    for line in horizontal_lines:
        did_append = False  # if True: line was found to be similar to another line already included in the averaged lines list
        for sub_list in avg_horizontal_lines:  # each sublist contains a cluster of lines found to be similar and to be averaged later
            for compare_line in sub_list:
                x1 = 0         
                x2 = image.shape[1]
                slope_cp = compare_line[0]
                intercept_cp = compare_line[1]
                slope_ln = line[0]
                intercept_ln = line[1]
                # compare the y coordinates at the two end points
                y_cp_1 = int(intercept_cp + slope_cp*x1)
                y_cp_2 = int(intercept_cp + slope_cp*x2)
                y_ln_1 = int(intercept_ln + slope_cp*x1)
                y_ln_2 = int(intercept_ln + slope_cp*x2)
                if abs(y_cp_1 - y_ln_1) > d_y or abs(y_cp_2 - y_ln_2) > d_y:    # if the lines are not similar (y coordinates are too far), end loop
                    break
            else:  # if loop was never broken, the lines are similar: append the new line in the compared sublist
                sub_list.append(line)
                did_append = True
        if not did_append:  # if the new line is not similar to any line, append it as a separate entry
            avg_horizontal_lines.append([line])
    avg_horizontal_lines_out = []  # output list for averaged horizontal lines
    avg_vertical_lines_out = []  # output list for averaged horizontal lines
    # go through each similar lines cluster and average them into a line (if just one line, the average will return the line itself)
    for sub_list in avg_vertical_lines:
        fit_average = np.average(sub_list, axis=0)
        line = make_points(image, fit_average)  # output line as [[x1,y1,x2,y2]]
        avg_vertical_lines_out.append(line)
    for sub_list in avg_horizontal_lines:
        fit_average = np.average(sub_list, axis=0)
        line = make_points(image, fit_average)  # output line as [[x1,y1,x2,y2]]
        avg_horizontal_lines_out.append(line)
    return avg_vertical_lines_out, avg_horizontal_lines_out


def determine_line_type(img, ln, trapz_type, color_low_1, color_high_1, color_threshold, color_low_2=None, color_high_2=None):
    """
    Determines if a line identified contains at least a threshold number of pixels in the color ranges provided

    :param img: an opencv image
    :param ln: a line defined by a nested list containing x and y coordinates of the first and second endpoints ([[x1, y1, x2, y2]])
    :param trapz_type: a switch to use different region of interest around the line depending on the type of the line
    :param color_low_1: color threshold in the HSV space ([H, S, V]) for the first lower limit
    :param color_high_1: color threshold in the HSV space ([H, S, V]) for the first upper limit
    :param color_threshold: if there are more pixels in the desired color range than this number, return True
    :param color_low_2: color threshold in the HSV space ([H, S, V]) for the second lower limit (to be used if Hue is wrapping around 0)
    :param color_high_2: color threshold in the HSV space ([H, S, V]) for the second upper limit (to be used if Hue is wrapping around 0)
    :return: True if the line is made up of enough pixels in the color ranges provided, False otherwise
    """
    height = img.shape[0]
    width = img.shape[1]
    mask = np.zeros_like(img)
    pts = ln[0]
    if trapz_type == 0:
        # for vertical lines
        trapz = np.array([[[
            (pts[0]-lane_rect, pts[1]),
            (pts[2]-lane_rect, pts[3]),
            (pts[2]+lane_rect, pts[3]),
            (pts[0]+lane_rect, pts[1]),]]], np.int32)

    elif trapz_type == 1:
        # for horizontal lines
        trapz = np.array([[[
            (pts[0], max(pts[1]-lane_rect,0)),
            (pts[2], max(pts[1]-lane_rect,0)),
            (pts[2], min(pts[3]+lane_rect,height)),
            (pts[0], min(pts[3]+lane_rect,height)),]]], np.int32)

    elif trapz_type == 2:
        # for horizontal stop lines, crop the sides of the line to avoid picking up pixels from a stop marker on the left for opposite direction traffic
        trapz = np.array([[[
            (pts[0]+170, max(pts[1]-lane_rect,0)),
            (pts[2]-170, max(pts[1]-lane_rect,0)),
            (pts[2]-170, min(pts[3]+lane_rect,height)),
            (pts[0]+170, min(pts[3]+lane_rect,height)),]]], np.int32)

    cv2.fillPoly(mask, trapz, [255,255,255])
    masked_image = cv2.bitwise_and(img, mask)  # get region of interest around line
    hsv_frame = cv2.cvtColor(masked_image, cv2.COLOR_BGR2HSV)  # convert ROI to HSV for color detection
    color_mask_1 = cv2.inRange(hsv_frame, color_low_1, color_high_1)  # color mask 1 (two are provided in case hue wraps around 0)
    if color_low_2 is not None and color_high_2 is not None:
        color_mask_2 = cv2.inRange(hsv_frame, color_low_2, color_high_2)
        color_mask = color_mask_1 | color_mask_2
    else:
        color_mask = color_mask_1
    color = cv2.bitwise_and(img, img, mask=color_mask)  # filter out desired color
    num_color = np.sum(color_mask)  # sum the number of pixels with the desired color
    if num_color > color_threshold:  # compare to threshold
        return True  # true: the line is in the color range desired
    else:
        return False


def callback(data):
    """
    Processes incoming image from the front camera of the Prius to detect lines of interest; publishes key points of the lines identifies

    :param data: sensor_msgs/Image message from the front camera of the Prius
    """
    try:
        cv_image = bridge.imgmsg_to_cv2(data, "bgr8")  # convert ROS image to opencv image
    except CvBridgeError as e:
        print(e)
    (rows,cols,channels) = cv_image.shape
    canny_image = canny(cv_image)  # apply Canny edge detector
    cropped_canny = region_of_interest(canny_image)  # crop image to throw away top and bottom regions (sky and front of the car)
    lines = cv2.HoughLinesP(cropped_canny, 2, np.pi/180, hough_threshold, np.array([]), minLineLength=min_line_length,maxLineGap=max_line_gap)  # extract lines
    if lines is not None:  # do the following if at least one line was extracted
        averaged_lines, stops = average_slope_intercept(cv_image, lines)  # classification and merging of lines
        types = []  # list to label each line to be published
        for ln in averaged_lines:  # for vertical lines, divide between central (yellow) and side lines
            if determine_line_type(cv_image, ln, 0, low_yellow, high_yellow, min_yellow_threshold):
                types.append(1)  # if line has yellow pixels: center line
            else:
                types.append(0)  # if line does not have yellow pixels: side line
        for ln in stops:  # for horizontal lines, find the stop markers
            if determine_line_type(cv_image, ln, 2, low_red_1, high_red_1, min_red_threshold, low_red_2, high_red_2):
                types.append(2)  # if line has red pixels: stop marker
                averaged_lines.append(ln)
            elif determine_line_type(cv_image, ln, 1, low_yellow, high_yellow, 3*min_yellow_threshold):
                types.append(3)  # if line has yellow pixels: horizontal center line
                averaged_lines.append(ln)
        line_image = display_lines(cv_image, averaged_lines, types)  # display the identified lines in different color on a blank image
        combined_image = cv2.addWeighted(cv_image, 0.8, line_image, 1, 1)  # superimpose lines to original image
        lane_data = Int32MultiArray()  # message to be published 
        lane_data_array = []  # contains each line summarized by a key point
        for ii in range(len(types)):
            if types[ii] == 0 or types[ii] == 1:  # for vertical lines, append top x coordinate
                lane_data_array.append(averaged_lines[ii][0][2])
            else:  # for horizontal lines, append a y coordinate
                lane_data_array.append(averaged_lines[ii][0][1])
            lane_data_array.append(types[ii])  # after the coordinate, append the type of the line
        lane_data.data = lane_data_array
        lanes_pub.publish(lane_data)
    else:  # if no lines detected
        combined_image = cv_image
    # resize the combined image for ease of visualization
    original_width = combined_image.shape[1]
    new_width = min(400, combined_image.shape[1])
    scale = new_width/original_width
    new_height = int(combined_image.shape[0]*scale)
    dim = (new_width, new_height)
    combined_image = cv2.resize(combined_image, dim, interpolation=cv2.INTER_AREA)
    try:
        image_pub.publish(bridge.cv2_to_imgmsg(combined_image, "bgr8"))  # convert from opencv image to ROS image and publish
    except CvBridgeError as e:
        print(e)


if __name__=="__main__":
    rospy.init_node('lanes')
    image_pub = rospy.Publisher("/my_lanes/image_raw",Image,queue_size=1)
    bridge = CvBridge()  # used to convert ROS images to opencv images and vice versa
    image_sub = rospy.Subscriber("/prius/front_camera/image_raw",Image,callback)
    lanes_pub = rospy.Publisher("/my_lanes/vals",Int32MultiArray,queue_size=2)

    hough_threshold = rospy.get_param("lanes/hough_threshold", 100)
    min_line_length = rospy.get_param("lanes/min_line_length", 40)
    max_line_gap = rospy.get_param("lanes/max_line_gap", 5)
    lane_rect = rospy.get_param("lanes/lane_rect", 8)
    min_red_threshold = rospy.get_param("lanes/min_red_threshold", 300000)
    min_yellow_threshold = rospy.get_param("lanes/min_yellow_threshold", 60000)
    min_hue_red = rospy.get_param("lanes/min_hue_red", 170)
    max_hue_red = rospy.get_param("lanes/max_hue_red", 10)
    min_hue_yellow = rospy.get_param("lanes/min_hue_yellow", 25)
    max_hue_yellow = rospy.get_param("lanes/max_hue_yellow", 40)
    min_vertical_slope = rospy.get_param("lanes/min_vertical_slope", 0.7)
    max_horizontal_slope = rospy.get_param("lanes/max_horizontal_slope", 0.15)
    d_x = rospy.get_param("lanes/same_vertical_line_gap", 10)
    d_y = rospy.get_param("lanes/same_horizontal_line_gap", 30)

    low_yellow = np.array([min_hue_yellow, 150, 64])
    high_yellow = np.array([max_hue_yellow, 255, 255])
    low_red_1 = np.array([min_hue_red,220,60])
    high_red_1 = np.array([180,255,255])
    low_red_2 = np.array([0,220,60])
    high_red_2 = np.array([max_hue_red,255,255])

    rospy.spin()